// docs/script.js (Logique du Frontend Compl√®te : Groq + ElevenLabs + Three.js)

// --- VARIABLES GLOBALES THREE.JS et AUDIO ---
let scene, camera, renderer, listener, cube;
let currentMesh; // Objet 3D actuellement affich√© (initialis√© dans initThreeJs)
const audioPlayerHTML = document.getElementById('audioPlayer');

// R√©f√©rences aux √©l√©ments de statut (ajout√©es pour √©viter les erreurs de r√©f√©rence)
const statusThreeJsElement = document.getElementById('statusThreeJs');
const statusGroqElement = document.getElementById('statusGroq');
const statusElevenLabsElement = document.getElementById('statusElevenLabs');


// --- INITIALISATION DE LA SC√àNE THREE.JS ---
function initThreeJs() {
    const canvas = document.getElementById('threeJsContainer'); 
    
    // Sc√®ne
    scene = new THREE.Scene();
    scene.background = new THREE.Color(0x222222);

    // Cam√©ra
    camera = new THREE.PerspectiveCamera(75, canvas.clientWidth / canvas.clientHeight, 0.1, 1000);
    camera.position.z = 5;

    // Rendu
    renderer = new THREE.WebGLRenderer({ 
        canvas: canvas, // Utilisation de l'√©l√©ment canvas existant
        antialias: true 
    });
    
    renderer.setSize(canvas.clientWidth, canvas.clientHeight);

    // Lumi√®re
    const light = new THREE.DirectionalLight(0xffffff, 1);
    light.position.set(0, 1, 1);
    scene.add(light);

    // Cube initial (Objet par d√©faut)
    const geometry = new THREE.BoxGeometry(1, 1, 1);
    const material = new THREE.MeshLambertMaterial({ color: 0xe74c3c });
    cube = new THREE.Mesh(geometry, material);
    scene.add(cube);
    currentMesh = cube; // D√©finir l'objet initial

    // AudioListener (attach√© √† la cam√©ra pour l'√©coute)
    listener = new THREE.AudioListener();
    camera.add(listener); 

    // Gestion de la boucle de rendu
    animate();
}

/**
 * Boucle d'animation rigoureuse pour Three.js.
 * G√®re la rotation de l'objet actif.
 */
function animate() {
    requestAnimationFrame(animate);

    if (currentMesh) {
        currentMesh.rotation.x += 0.005;
        currentMesh.rotation.y += 0.005;
    }

    renderer.render(scene, camera);
}

// Lancer l'initialisation apr√®s le chargement du DOM
initThreeJs();


// --- GESTIONNAIRES D'√âV√âNEMENTS ---

// 1. G√©n√©ration de Forme 3D (Groq Three.js)
document.getElementById('threeJsForm').addEventListener('submit', async function(event) {
    event.preventDefault();

    const promptInput = document.getElementById('threeJsPrompt').value;
    statusThreeJsElement.textContent = 'üß† Groq g√©n√®re la forme 3D...';

    try {
        const response = await fetch('/groqThreeJs', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ prompt: promptInput })
        });

        if (!response.ok) {
            const errorText = await response.text();
            throw new Error(`Erreur Groq 3D: ${errorText}`);
        }
        
        const data = await response.json();

        if (data.error) {
            statusThreeJsElement.textContent = `‚ùå Erreur de formatage : ${data.error}`;
            return;
        }

        // --- Logique d'application de la forme 3D ---
        const { type, parameters, color } = data;
        let geometry;

        // D√©terminer le type de G√©om√©trie et instancier
        switch (type) {
            case 'BoxGeometry':
                geometry = new THREE.BoxGeometry(...parameters);
                break;
            case 'SphereGeometry':
                geometry = new THREE.SphereGeometry(...parameters);
                break;
            case 'CylinderGeometry':
                geometry = new THREE.CylinderGeometry(...parameters);
                break;
            default:
                throw new Error(`Type de g√©om√©trie non support√©: ${type}`);
        }
        
        // Cr√©er le Mat√©riau et le Mesh
        const material = new THREE.MeshLambertMaterial({ color: new THREE.Color(color) });
        const newMesh = new THREE.Mesh(geometry, material);

        // Remplacer l'ancien Mesh
        if (currentMesh) {
            scene.remove(currentMesh);
            currentMesh.geometry.dispose();
            currentMesh.material.dispose();
        }
        
        // Ajouter le nouvel objet
        newMesh.position.set(0, 0, 0);
        scene.add(newMesh);
        currentMesh = newMesh;
        
        statusThreeJsElement.textContent = `‚úÖ Forme 3D (${type}) g√©n√©r√©e et ajout√©e √† la sc√®ne.`;

    } catch (error) {
        console.error('Erreur Groq 3D:', error);
        statusThreeJsElement.textContent = `‚ùå Erreur 3D : ${error.message}`;
    }
});


// 2. G√©n√©ration de Texte (Groq Llama)
document.getElementById('groqForm').addEventListener('submit', async function(event) {
    event.preventDefault();

    const promptInput = document.getElementById('promptInput').value;
    const textInput = document.getElementById('textInput'); 
    const outputTextInput = document.getElementById('outputTextInput'); 

    statusGroqElement.textContent = 'üß† Groq g√©n√®re le texte...';
    textInput.value = ''; 
    outputTextInput.value = ''; 

    try {
        const response = await fetch('/generate-text', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ prompt: promptInput })
        });

        if (!response.ok) {
            const errorText = await response.text();
            throw new Error(`Erreur Groq: ${errorText}`);
        }
        
        const data = await response.json();
        
        textInput.value = data.text;
        outputTextInput.value = data.text; 
        statusGroqElement.textContent = '‚úÖ Texte g√©n√©r√© par Groq, pr√™t pour la voix.';

    } catch (error) {
        console.error('Erreur Groq:', error);
        statusGroqElement.textContent = `‚ùå Erreur lors de la g√©n√©ration Groq : ${error.message}`;
    }
});


// 3. Synth√®se Vocale (ElevenLabs) et Int√©gration Three.js Audio
document.getElementById('ttsForm').addEventListener('submit', async function(event) {
    event.preventDefault();

    const textToSpeak = document.getElementById('textInput').value;
    
    if (!textToSpeak) {
        statusElevenLabsElement.textContent = 'Veuillez g√©n√©rer ou saisir du texte d\'abord.';
        return;
    }

    statusElevenLabsElement.textContent = 'üéôÔ∏è ElevenLabs g√©n√®re l\'audio pour la sc√®ne 3D...';
    audioPlayerHTML.src = ''; 

    try {
        const response = await fetch('/generate-audio', {
            method: 'POST',
            headers: { 'Content-Type': 'application/json' },
            body: JSON.stringify({ text: textToSpeak })
        });

        if (!response.ok) {
            const errorText = await response.text();
            throw new Error(`Erreur ElevenLabs: ${errorText}`);
        }
        
        const audioBlob = await response.blob();
        
        // Charger le Blob Audio dans le Web Audio API de Three.js (m√©thode rigoureuse)
        const sound = new THREE.Audio(listener);
        const audioContext = listener.context;
        const fileReader = new FileReader();

        fileReader.onload = function(e) {
            audioContext.decodeAudioData(e.target.result, function(buffer) {
                sound.setBuffer(buffer);
                sound.setVolume(0.5); 
                
                // --- Action 3D li√©e √† la Voix (Exemple d'animation de la cam√©ra) ---
                const initialColor = currentMesh.material.color.getHex();
                
                // Mouvement et changement de couleur au d√©but de la lecture
                if (currentMesh) {
                    currentMesh.material.color.setHex(0x3498db); // Couleur bleue active
                    camera.position.z = 4; // Zoom l√©ger
                }

                sound.onEnded = function() {
                    // R√©tablir les √©tats apr√®s la lecture
                    if (currentMesh) {
                        currentMesh.material.color.setHex(initialColor);
                    }
                    camera.position.z = 5; 
                };
                
                sound.play(); 
                statusElevenLabsElement.textContent = 'üîä Audio pr√™t et en lecture dans la sc√®ne 3D.';

                // Optionnel: Lecture via le lecteur HTML aussi (pour le contr√¥le natif)
                const audioUrl = URL.createObjectURL(audioBlob);
                audioPlayerHTML.src = audioUrl;

            }, function(e) {
                console.error('Erreur de d√©codage audio:', e);
                statusElevenLabsElement.textContent = '‚ùå Erreur : D√©coding Audio Failed.';
            });
        };
        
        fileReader.readAsArrayBuffer(audioBlob);
        
    } catch (error) {
        console.error('Erreur ElevenLabs:', error);
        statusElevenLabsElement.textContent = `‚ùå Erreur lors de la synth√®se vocale : ${error.message}`;
    }
});